{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bambi as bmb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from IPython.display import display\n",
    "from scipy import stats\n",
    "import pymc as py\n",
    "import arviz as az\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "soci_data = pd.read_csv(\"C:/Users/LauflaborVR2/GS-MT_Test/Data/main_presence_questionaire.csv\")\n",
    "heights = soci_data[\"Height\"]\n",
    "weights = soci_data[\"Weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei nicht gefunden: C:/Users/LauflaborVR2/GS-MT_Test/Data/08Baseline.csv\n",
      "Datei nicht gefunden: C:/Users/LauflaborVR2/GS-MT_Test/Data/09Baseline.csv\n",
      "Datei nicht gefunden: C:/Users/LauflaborVR2/GS-MT_Test/Data/10Baseline.csv\n",
      "Datei nicht gefunden: C:/Users/LauflaborVR2/GS-MT_Test/Data/11Baseline.csv\n",
      "Datei nicht gefunden: C:/Users/LauflaborVR2/GS-MT_Test/Data/12Baseline.csv\n",
      "Datei nicht gefunden: C:/Users/LauflaborVR2/GS-MT_Test/Data/13Baseline.csv\n",
      "Datei nicht gefunden: C:/Users/LauflaborVR2/GS-MT_Test/Data/14Baseline.csv\n",
      "Datei nicht gefunden: C:/Users/LauflaborVR2/GS-MT_Test/Data/15Baseline.csv\n",
      "Datei nicht gefunden: C:/Users/LauflaborVR2/GS-MT_Test/Data/16Baseline.csv\n",
      "Datei nicht gefunden: C:/Users/LauflaborVR2/GS-MT_Test/Data/17Baseline.csv\n"
     ]
    }
   ],
   "source": [
    "with open('combined_step_analysis_results_with_arrays.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Flatten JSON into a structured DataFrame\n",
    "flat_data = []\n",
    "\n",
    "for participant, conditions in data.items():\n",
    "    for condition, trials in conditions.items():\n",
    "        for trial, metrics in trials.items():\n",
    "            # Extract only the required scalar value for velocity (assuming velocity_mean_l is a float, not a list)\n",
    "            if isinstance(metrics[\"mean_velocity\"], list):\n",
    "                # If velocity_mean_l is somehow a list, take the mean or handle appropriately\n",
    "                velocity = sum(metrics[\"mean_velocity\"]) / len(metrics[\"mean_velocity\"])\n",
    "            else:\n",
    "                velocity = metrics[\"mean_velocity\"]\n",
    "\n",
    "            row = {\n",
    "                \"Participant\": participant,\n",
    "                \"Condition\": condition,\n",
    "                \"Trial\": trial,\n",
    "                \"Velocity\": velocity, \n",
    "                \"numStrides_r\": metrics[\"numStrides_r\"],\n",
    "                \"numStrides_l\": metrics[\"numStrides_l\"],\n",
    "                \"RoM_ankle_l\": metrics[\"footAngle_l\"],\n",
    "                \"RoM_knee_l\": metrics[\"kneeAngle_l\"],\n",
    "                \"RoM_ankle_r\": metrics[\"footAngle_r\"],\n",
    "                \"RoM_knee_r\": metrics[\"kneeAngle_r\"],\n",
    "                \"Walking_distance\": metrics[\"walking_distance_r\"],\n",
    "            }\n",
    "            flat_data.append(row)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(flat_data)\n",
    "\n",
    "df['Participant'] = df['Participant'].str.extract('(\\d+)').astype(int)\n",
    "df['Condition'] = df['Condition'].str.extract('(\\d+)').astype(int)\n",
    "df['Trial'] = df['Trial'].str.extract('(\\d+)').astype(int)\n",
    "# Convert categorical variables\n",
    "df['Participant'] = df['Participant'].astype('category')\n",
    "df['Condition'] = df['Condition'].astype('category')\n",
    "\n",
    "#normalize velocity\n",
    "velocity_min = df['Velocity'].min()\n",
    "velocity_max = df['Velocity'].max()\n",
    "\n",
    "# Min-Max Normalisierung der Velocity-Daten\n",
    "df['Velocity_normalized'] = (df['Velocity'] - velocity_min) / (velocity_max - velocity_min)\n",
    "\n",
    "unique_participants = df['Participant'].unique()\n",
    "participant_height_dict = dict(zip(unique_participants, heights))\n",
    "df[\"Height\"] = df[\"Participant\"].map(participant_height_dict)\n",
    "participant_weight_dict = dict(zip(unique_participants, weights))\n",
    "df[\"Weight\"] = df[\"Participant\"].map(participant_weight_dict)\n",
    "\n",
    "embodi_data = {}\n",
    "conditions =[\"Baseline\", \"NoAvatar\", \"Normal\", \"Small\", \"Large\"]\n",
    "for c in df['Condition'].unique():\n",
    "    if c== 0:\n",
    "        continue\n",
    "\n",
    "    temp = {}\n",
    "    cond = conditions[c-1]\n",
    "    for p in df['Participant'].unique():\n",
    "        if p< 10:\n",
    "            file_path = f\"C:/Users/LauflaborVR2/GS-MT_Test/Data/0{p}{cond}.csv\"\n",
    "        else:\n",
    "             file_path = f\"C:/Users/LauflaborVR2/GS-MT_Test/Data/{p}{cond}.csv\"\n",
    "        try:\n",
    "            d = pd.read_csv(file_path, names=[\"Question\", \"Value\"])\n",
    "            temp[p] = d\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Datei nicht gefunden: {file_path}\")\n",
    "    embodi_data[c] = temp\n",
    "\n",
    "# Fragebogendaten dem DataFrame df hinzuf端gen\n",
    "question_columns = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12']\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    participant = row['Participant']\n",
    "    condition = row['Condition']\n",
    "\n",
    "    # Fragebogendaten nur hinzuf端gen, wenn es sich nicht um die Baseline-Bedingung handelt\n",
    "    if condition != 0 and condition in embodi_data and participant in embodi_data[condition]:\n",
    "        survey_data = embodi_data[condition][participant]\n",
    "        # Berechnung der Mittelwerte f端r \"Ownership\", \"Agency\" und \"Change\"\n",
    "        ownership_mean = survey_data['Value'].iloc[:4].mean()\n",
    "        agency_mean = survey_data['Value'].iloc[4:8].mean()\n",
    "        change_mean = survey_data['Value'].iloc[8:12].mean()\n",
    "        \n",
    "        # Mittelwerte dem DataFrame hinzuf端gen\n",
    "        df.at[index, 'Ownership'] = ownership_mean\n",
    "        df.at[index, 'Agency'] = agency_mean\n",
    "        df.at[index, 'Change'] = change_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2.905574\n",
       "1      2.844447\n",
       "2      2.741849\n",
       "3      2.794128\n",
       "4      2.840076\n",
       "         ...   \n",
       "443    2.986257\n",
       "444    2.937250\n",
       "445    3.073988\n",
       "446    3.044719\n",
       "447    3.010452\n",
       "Name: Walking_distance, Length: 448, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Walking_distance\"]/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bmb.Model(\"Velocity_normalized ~  Condition + Height \", data= df) # (1 | x) is a random intercept  + (1|Participant)\n",
    "fitted = model.fit( \n",
    "    draws=1000, \n",
    "    tune= 500,\n",
    "    # init=\"adapt_diag\", \n",
    "    # random_seed=69,\n",
    "    cores=8,\n",
    "    #chains=8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(\n",
    "    fitted,\n",
    "    var_names=[\"Intercept\", \"Condition\", \"sigma\"],\n",
    "    compact=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc = model.predict(idata=fitted, kind=\"pps\", inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ppc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ppc_samples = ppc.posterior_predictive\n",
    "print(ppc_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_ppc(ppc, var_names=[\"NumStrides\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
